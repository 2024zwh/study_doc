## ä¸€ã€AI Agent

### 1.å®šä¹‰

> AI Agent ä¸æ˜¯ä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äººï¼Œè€Œæ˜¯å…·æœ‰ç›®æ ‡å¯¼å‘æ€§ï¼Œè‡ªä¸»æ€§å’Œè‡ªé€‚åº”çš„æ™ºèƒ½ä½“ã€‚AI Agentæ˜¯ä¸€ä¸ªèƒ½å¤Ÿæ„ŸçŸ¥ç¯å¢ƒï¼Œè‡ªä¸»å†³ç­–ï¼Œæ‰§è¡ŒåŠ¨ä½œï¼Œå¹¶ä¸”æŒç»­è¿½å¯»ç›®æ ‡çš„æ™ºèƒ½ç³»ç»Ÿã€‚
>
> æ ¸å¿ƒæ€æƒ³ï¼š**AI Agent = LLMï¼ˆå¤§è„‘ï¼‰ + Memoryï¼ˆè®°å¿†ï¼‰ + Toolsï¼ˆæ‰‹è„šï¼‰ + Planningï¼ˆæ€ç»´ï¼‰ + Loopï¼ˆè¿­ä»£ï¼‰**

### 2.å››å¤§èƒ½åŠ›

| èƒ½åŠ›                      | è¯´æ˜                     | æŠ€æœ¯å®ç°ç¤ºä¾‹                                               |
| ------------------------- | ------------------------ | ---------------------------------------------------------- |
| æ„ŸçŸ¥ï¼ˆ**Perception**ï¼‰    | è·å–å¤–éƒ¨ä¿¡æ¯ï¼Œç†è§£ä¸Šä¸‹æ–‡ | æ¥æ”¶ç”¨æˆ·è¾“å…¥ã€è¯»å–æ–‡ä»¶ã€è°ƒç”¨APIã€è§£æç½‘é¡µ                  |
| è§„åˆ’ï¼ˆ**Planning**ï¼‰      | å¯¹ç›®æ ‡è¿›è¡Œæ‹†åˆ†æ­¥éª¤       | ä»»åŠ¡åˆ†è§£ï¼ˆTask Decompositionï¼‰ã€æ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼‰ |
| è®°å¿†ï¼ˆ**memory**ï¼‰        | å­˜å‚¨å’Œè°ƒç”¨å†å²ä¿¡æ¯       | çŸ­æœŸè®°å¿†ï¼ˆä¸Šä¸‹æ–‡ï¼‰ã€é•¿æœŸè®°å¿†ï¼ˆè°ƒç”¨å‘é‡æ•°æ®åº“ï¼‰             |
| å·¥å…·ä½¿ç”¨ï¼ˆ**Tools Use**ï¼‰ | è°ƒç”¨å¤–éƒ¨èƒ½åŠ›æ‰©å±•è‡ªèº«åŠŸèƒ½ | æœç´¢ã€ä»£ç æ‰§è¡Œã€æ•°æ®åº“æŸ¥è¯¢ã€å‘é€é‚®ä»¶ç­‰                     |

> âœ… **å…³é”®åŒºåˆ«**ï¼šä¼ ç»ŸAIæ¨¡å‹ï¼ˆå¦‚GPTï¼‰æ˜¯â€œè¢«åŠ¨å“åº”â€ï¼Œè€ŒAI Agentæ˜¯â€œä¸»åŠ¨æ‰§è¡Œâ€ã€‚



### 3.åŸºæœ¬æ„æ¶

```
ç”¨æˆ·è¾“å…¥
  â†“
æ„ŸçŸ¥æ¨¡æ¿       ï¼ˆç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ï¼Œå›¾ç‰‡ï¼Œè§†é¢‘ç­‰ï¼‰
  â†“
è§„åˆ’æ¨¡å—       ï¼ˆå¯¹ç”¨æˆ·çš„éœ€æ±‚ï¼Œè¿›è¡Œä»»åŠ¡æ‹†è§£å’Œè§„åˆ’ï¼‰
  â†“
å†³ç­–å’Œæ¨ç†æ¨¡å—  ï¼ˆLLMä½œä¸ºå¤§è„‘è¿›è¡Œæ€è€ƒå’Œå†³ç­– ï¼‰
  â†“
å·¥å…·è°ƒç”¨æ¨¡å—   ï¼ˆè°ƒç”¨å¤–éƒ¨å·¥å…·ï¼Œæ¯”å¦‚è°ƒç”¨æœç´¢ã€ä»£ç è§£é‡Šå™¨ã€APIç­‰ï¼‰
  â†“
æ‰§è¡ŒåŠ¨ä½œæ¨¡å—   ï¼ˆè¾“å‡ºç»“æœã€ä¿®æ”¹çŠ¶æ€ã€å‘é€è¯·æ±‚ï¼‰
  â†“
è®°å¿†æ¨¡å—       ï¼ˆå­˜å‚¨ä¸Šä¸‹æ–‡ã€ç»éªŒã€çŸ¥è¯†ï¼‰
  â†“
ç¯å¢ƒåé¦ˆæ¨¡å—    ï¼ˆè§‚å¯Ÿæ‰§è¡Œç»“æœï¼Œå†³å®šæ˜¯å¦é‡è¯•æˆ–è°ƒæ•´ï¼‰
```

### 4.æ ¸å¿ƒèƒ½åŠ›è¯¦è§£

#### 1. **LLM ä½œä¸ºâ€œå¤§è„‘â€ï¼ˆReasoning Engineï¼‰**

- Agent çš„æ ¸å¿ƒæ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPT-4ã€Claudeã€Llamaï¼‰ã€‚
- å®ƒè´Ÿè´£ï¼š
  - ç†è§£ç”¨æˆ·æ„å›¾
  - ç”Ÿæˆè®¡åˆ’
  - åšå‡ºå†³ç­–
  - è°ƒç”¨å·¥å…·çš„åˆ¤æ–­
- å…³é”®æœºåˆ¶ï¼š
  - **Function Calling / Tool Calling**ï¼šè®©LLMâ€œçŸ¥é“â€å®ƒå¯ä»¥è°ƒç”¨å“ªäº›å·¥å…·ã€‚

#### 2.**è®°å¿†ï¼ˆMemoryï¼‰**

| ç±»å‹         | è¯´æ˜                         | ç¤ºä¾‹                           |
| ------------ | ---------------------------- | ------------------------------ |
| **çŸ­æœŸè®°å¿†** | ä¿å­˜å½“å‰ä¼šè¯ä¸Šä¸‹æ–‡           | `ConversationBufferMemory`     |
| **é•¿æœŸè®°å¿†** | è·¨ä¼šè¯ã€è·¨ä»»åŠ¡çš„çŸ¥è¯†å­˜å‚¨     | å‘é‡æ•°æ®åº“ï¼ˆChroma, Pineconeï¼‰ |
| **å®ä½“è®°å¿†** | è®°ä½å…³é”®å®ä½“ï¼ˆå¦‚äººåã€åœ°ç‚¹ï¼‰ | è®°å½•â€œç”¨æˆ·å–œæ¬¢ç§‘æŠ€ç±»æ–‡ç« â€       |

> ğŸ“Œ è®°å¿†æ˜¯Agentâ€œæˆé•¿â€çš„åŸºç¡€ï¼Œé¿å…æ¯æ¬¡ä»é›¶å¼€å§‹ã€‚

#### 3. **å·¥å…·ï¼ˆToolsï¼‰**

Agent é€šè¿‡å·¥å…·æ‰©å±•èƒ½åŠ›ï¼Œå¸¸è§å·¥å…·åŒ…æ‹¬ï¼š

- `SearchTool`ï¼šè”ç½‘æœç´¢ï¼ˆå¦‚Tavilyã€SerpAPIï¼‰
- `CodeInterpreterTool`ï¼šæ‰§è¡ŒPythonä»£ç ï¼ˆè®¡ç®—ã€ç»˜å›¾ã€æ•°æ®å¤„ç†ï¼‰
- `GmailTool`ï¼šå‘é€é‚®ä»¶
- `FileTool`ï¼šè¯»å†™æ–‡ä»¶
- `Calculator`ï¼šæ•°å­¦è®¡ç®—
- `Custom API`ï¼šè°ƒç”¨ä¼ä¸šå†…éƒ¨ç³»ç»Ÿ

> âœ… Agent çš„èƒ½åŠ› = LLM + å·¥å…·åº“

#### 4. **è§„åˆ’ï¼ˆPlanningï¼‰**

Agent å¦‚ä½•æ€è€ƒå’Œæ‹†è§£ä»»åŠ¡ï¼Ÿå¸¸è§ç­–ç•¥ï¼š

| ç­–ç•¥                                       | è¯´æ˜                                                         |
| ------------------------------------------ | ------------------------------------------------------------ |
| å•æ­¥å¾ªç¯ï¼ˆ **Zero-shot ReAct** ï¼‰          | LLM ç›´æ¥æ€è€ƒ â†’ è¡ŒåŠ¨ â†’ è§‚å¯Ÿ â†’ å†æ€è€ƒï¼ˆå•æ­¥å¾ªç¯ï¼‰              |
| å¤šè·¯æœ€ä¼˜é€‰æ‹©ï¼ˆ**Tree of Thoughts (ToT)**ï¼‰ | ç”Ÿæˆå¤šä¸ªå¯èƒ½æ€è·¯ï¼Œè¯„ä¼°åé€‰æ‹©æœ€ä¼˜è·¯å¾„                         |
| å¤§ä»»åŠ¡æ‹†è§£å°ä»»åŠ¡ï¼ˆ**Task Decomposition**ï¼‰ | å°†å¤§ä»»åŠ¡æ‹†åˆ†ä¸ºå­ä»»åŠ¡ï¼ˆå¦‚â€œå†™æŠ¥å‘Šâ€ â†’ æŸ¥èµ„æ–™ â†’ å†™å¤§çº² â†’ å†™æ­£æ–‡ï¼‰ |
| è‡ªæˆ‘æ€è€ƒï¼Œé‡è¯•ï¼ˆ**Reflexion**ï¼‰            | æ‰§è¡Œå¤±è´¥åè‡ªæˆ‘åæ€ï¼Œè°ƒæ•´ç­–ç•¥é‡è¯•                             |

#### 5. **çŠ¶æ€ç®¡ç†ï¼ˆState Managementï¼‰**

- åœ¨å¤æ‚ä»»åŠ¡ä¸­ï¼ŒAgent éœ€è¦ç»´æŠ¤ä¸€ä¸ª

  å…±äº«çŠ¶æ€ï¼ˆStateï¼‰ï¼Œè®°å½•ï¼š

  - å½“å‰ä»»åŠ¡
  - å·²å®Œæˆæ­¥éª¤
  - ä¸­é—´ç»“æœ
  - é”™è¯¯æ—¥å¿—

- **LangGraph** æ­£æ˜¯åŸºäºâ€œçŠ¶æ€æœºâ€ï¼ˆState Machineï¼‰æ¥ç®¡ç†è¿™ç§å¤æ‚æµç¨‹ã€‚



### 5.AI Agent çš„ç±»å‹

| ç±»å‹                 | ç‰¹ç‚¹                             | ç¤ºä¾‹                                |
| -------------------- | -------------------------------- | ----------------------------------- |
| **ååº”å¼ Agent**     | æ„ŸçŸ¥ â†’ ç«‹å³è¡ŒåŠ¨ï¼Œæ— é•¿æœŸè®°å¿†      | ç®€å•å®¢æœæœºå™¨äºº                      |
| **åŸºäºæ¨¡å‹çš„ Agent** | ç»´æŠ¤å†…éƒ¨çŠ¶æ€æ¨¡å‹ï¼Œèƒ½å¤„ç†éƒ¨åˆ†å†å² | å¸¦è®°å¿†çš„èŠå¤©æœºå™¨äºº                  |
| **ç›®æ ‡é©±åŠ¨ Agent**   | ä¸ºè¾¾æˆç›®æ ‡è‡ªä¸»è§„åˆ’å’Œæ‰§è¡Œ         | AutoGPTã€BabyAGI                    |
| **å¤š Agent ç³»ç»Ÿ**    | å¤šä¸ªAgentåä½œå®Œæˆä»»åŠ¡            | Researcher + Writer + Reviewer å›¢é˜Ÿ |
| **è‡ªæ²» Agent**       | é•¿æœŸè¿è¡Œï¼Œè‡ªæˆ‘ç»´æŠ¤å’Œä¼˜åŒ–         | æ•°å­—å‘˜å·¥ã€AIåŠ©æ‰‹                    |

### 6.AI Agent çš„æŒ‘æˆ˜ä¸å±€é™

| æŒ‘æˆ˜                      | è¯´æ˜                                         |
| ------------------------- | -------------------------------------------- |
| **å¹»è§‰ï¼ˆHallucinationï¼‰** | LLM å¯èƒ½ç¼–é€ è™šå‡ä¿¡æ¯æˆ–é”™è¯¯è°ƒç”¨å·¥å…·           |
| **æ•ˆç‡é—®é¢˜**              | å¤šæ¬¡è°ƒç”¨LLMå¯¼è‡´å»¶è¿Ÿå’Œæˆæœ¬é«˜                  |
| **å®‰å…¨æ€§**                | å¯èƒ½æ‰§è¡Œå±é™©æ“ä½œï¼ˆå¦‚åˆ é™¤æ–‡ä»¶ã€å‘é€é”™è¯¯é‚®ä»¶ï¼‰ |
| **å¯è§£é‡Šæ€§å·®**            | â€œé»‘ç®±â€å†³ç­–ï¼Œéš¾ä»¥è¿½è¸ªé”™è¯¯åŸå›                  |
| **é•¿æœŸç¨³å®šæ€§**            | å¤æ‚ä»»åŠ¡å¯èƒ½é™·å…¥æ­»å¾ªç¯æˆ–å´©æºƒ                 |

### 7.AI Agent çš„åº”ç”¨åœºæ™¯

| é¢†åŸŸ           | åº”ç”¨æ¡ˆä¾‹                         |
| -------------- | -------------------------------- |
| **åŠå…¬è‡ªåŠ¨åŒ–** | è‡ªåŠ¨ç”Ÿæˆå‘¨æŠ¥ã€ä¼šè®®çºªè¦ã€PPT      |
| **å®¢æˆ·æœåŠ¡**   | æ™ºèƒ½å®¢æœã€è®¢å•æŸ¥è¯¢ã€é—®é¢˜è§£å†³     |
| **ç ”å‘è¾…åŠ©**   | ä»£ç ç”Ÿæˆã€Bug ä¿®å¤ã€æ–‡æ¡£ç¼–å†™     |
| **æ•°æ®åˆ†æ**   | è‡ªåŠ¨çˆ¬å–æ•°æ®ã€æ¸…æ´—ã€åˆ†æã€å¯è§†åŒ– |
| **å†…å®¹åˆ›ä½œ**   | å†™æ–‡ç« ã€è„šæœ¬ã€è¥é”€æ–‡æ¡ˆã€å°è¯´     |
| **ä¸ªäººåŠ©ç†**   | å®‰æ’è¡Œç¨‹ã€è®¢é¤ã€æŸ¥å¤©æ°”ã€å­¦ä¹ è¾…å¯¼ |
| **é‡‘èæŠ•èµ„**   | è‚¡ç¥¨åˆ†æã€é£é™©è¯„ä¼°ã€è‡ªåŠ¨åŒ–äº¤æ˜“   |

## äºŒã€langchian

> **LangChain** æ˜¯ä¸€ä¸ªç”¨äºå¼€å‘ç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é©±åŠ¨çš„åº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚

### 1.æ¶æ„

> LangChain æ˜¯ä¸€ä¸ªç”±å¤šä¸ªåŒ…ç»„æˆçš„æ¡†æ¶

#### langchain-core

> æ­¤åŒ…åŒ…å«ä¸åŒç»„ä»¶çš„åŸºç¡€æŠ½è±¡ä»¥åŠå°†å®ƒä»¬ç»„åˆåœ¨ä¸€èµ·çš„æ–¹å¼ã€‚æ ¸å¿ƒç»„ä»¶ï¼ˆå¦‚èŠå¤©æ¨¡å‹ã€å‘é‡å­˜å‚¨ã€å·¥å…·ç­‰ï¼‰çš„æ¥å£åœ¨æ­¤å¤„å®šä¹‰ã€‚æ­¤å¤„æœªå®šä¹‰ä»»ä½•ç¬¬ä¸‰æ–¹é›†æˆã€‚ä¾èµ–é¡¹éå¸¸è½»é‡ã€‚

#### langchain

> ä¸» `langchain` åŒ…åŒ…å«æ„æˆåº”ç”¨ç¨‹åºè®¤çŸ¥æ¶æ„çš„é“¾å’Œæ£€ç´¢ç­–ç•¥ã€‚è¿™äº›ä¸æ˜¯ç¬¬ä¸‰æ–¹é›†æˆã€‚æ­¤å¤„çš„æ‰€æœ‰é“¾ã€ä»£ç†å’Œæ£€ç´¢ç­–ç•¥å¹¶éç‰¹å®šäºä»»ä½•ä¸€ä¸ªé›†æˆï¼Œè€Œæ˜¯é€‚ç”¨äºæ‰€æœ‰é›†æˆçš„é€šç”¨ç­–ç•¥ã€‚

#### é›†æˆè½¯ä»¶åŒ…

> æµè¡Œçš„é›†æˆæœ‰å®ƒä»¬è‡ªå·±çš„åŒ…ï¼ˆä¾‹å¦‚ `langchain-openai`ã€`langchain-anthropic` ç­‰ï¼‰ï¼Œä»¥ä¾¿å®ƒä»¬å¯ä»¥æ­£ç¡®åœ°è¿›è¡Œç‰ˆæœ¬æ§åˆ¶å¹¶ä¿æŒé€‚å½“çš„è½»é‡çº§ã€‚

æ›´å¤šä¿¡æ¯è¯·å‚é˜…

- é›†æˆåŒ…åˆ—è¡¨
- æ‚¨å¯ä»¥åœ¨å…¶ä¸­æ‰¾åˆ°æ¯ä¸ªé›†æˆåŒ…è¯¦ç»†ä¿¡æ¯çš„ [API å‚è€ƒ](https://python.langchain.ac.cn/api_reference/)ã€‚

#### langchain-community

> æ­¤åŒ…åŒ…å«ç”± LangChain ç¤¾åŒºç»´æŠ¤çš„ç¬¬ä¸‰æ–¹é›†æˆã€‚å…³é”®é›†æˆåŒ…å·²åˆ†ç¦»å‡ºæ¥ï¼ˆå‚è§ä¸Šæ–‡ï¼‰ã€‚è¿™åŒ…å«å„ç§ç»„ä»¶ï¼ˆèŠå¤©æ¨¡å‹ã€å‘é‡å­˜å‚¨ã€å·¥å…·ç­‰ï¼‰çš„é›†æˆã€‚æ­¤åŒ…ä¸­çš„æ‰€æœ‰ä¾èµ–é¡¹éƒ½æ˜¯å¯é€‰çš„ï¼Œä»¥å°½å¯èƒ½ä¿æŒåŒ…çš„è½»é‡çº§ã€‚

#### langgraph

> `langgraph` æ˜¯ `langchain` çš„ä¸€ä¸ªæ‰©å±•ï¼Œæ—¨åœ¨é€šè¿‡å°†æ­¥éª¤å»ºæ¨¡ä¸ºå›¾ä¸­çš„è¾¹å’ŒèŠ‚ç‚¹ï¼Œä½¿ç”¨ LLM æ„å»ºå¥å£®çš„æœ‰çŠ¶æ€å¤šä»£ç†åº”ç”¨ç¨‹åºã€‚LangGraph æä¾›äº†ç”¨äºåˆ›å»ºå¸¸è§ç±»å‹ä»£ç†çš„é«˜çº§æ¥å£ï¼Œä»¥åŠç”¨äºç»„åˆè‡ªå®šä¹‰æµç¨‹çš„ä½çº§ APIã€‚

å»¶ä¼¸é˜…è¯»

- æŸ¥çœ‹æˆ‘ä»¬çš„ LangGraph æ¦‚è¿° [æ­¤å¤„](https://github.langchain.ac.cn/langgraph/concepts/high_level/#core-principles)ã€‚
- æŸ¥çœ‹æˆ‘ä»¬çš„ LangGraph å­¦é™¢è¯¾ç¨‹ [æ­¤å¤„](https://academy.langchain.com/courses/intro-to-langgraph)ã€‚

#### langserve

> ä¸€ä¸ªç”¨äºå°† LangChain é“¾éƒ¨ç½²ä¸º REST API çš„åŒ…ã€‚è¿™ä½¿å¾—éƒ¨ç½²ç”Ÿäº§å°±ç»ªçš„ API å˜å¾—å®¹æ˜“ã€‚

é‡è¦

LangServe ä¸»è¦è®¾è®¡ç”¨äºéƒ¨ç½²ç®€å•çš„ Runnable å¹¶ä¸ langchain-core ä¸­ä¼—æ‰€å‘¨çŸ¥çš„åŸè¯­ååŒå·¥ä½œã€‚

å¦‚æœæ‚¨éœ€è¦ LangGraph çš„éƒ¨ç½²é€‰é¡¹ï¼Œæ‚¨åº”è¯¥æŸ¥çœ‹ LangGraph å¹³å°ï¼ˆæµ‹è¯•ç‰ˆï¼‰ï¼Œå®ƒæ›´é€‚åˆéƒ¨ç½² LangGraph åº”ç”¨ç¨‹åºã€‚

æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [LangServe æ–‡æ¡£](https://python.langchain.ac.cn/docs/langserve/)ã€‚

#### LangSmith

> ä¸€ä¸ªå¼€å‘è€…å¹³å°ï¼Œå¯è®©æ‚¨è°ƒè¯•ã€æµ‹è¯•ã€è¯„ä¼°å’Œç›‘æ§ LLM åº”ç”¨ç¨‹åºã€‚

æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [LangSmith æ–‡æ¡£](https://langsmith.langchain.ac.cn/)

### 2.æ ¸å¿ƒæ¨¡å—

#### 2.1 èŠå¤©æ¨¡å‹ï¼ˆLLMï¼‰

##### 2.1.1 ä»€ä¹ˆæ˜¯èŠå¤©æ¨¡å‹ï¼Ÿ

**èŠå¤©æ¨¡å‹ï¼ˆChat Modelï¼‰** æ˜¯ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸»æµäº¤äº’æ–¹å¼ã€‚å®ƒæ¥æ”¶ä¸€ä¸ª**æ¶ˆæ¯åˆ—è¡¨**ä½œä¸ºè¾“å…¥ï¼Œè¿”å›ä¸€æ¡**æ¶ˆæ¯**ä½œä¸ºè¾“å‡ºã€‚

ä¸ä¼ ç»Ÿçš„â€œå­—ç¬¦ä¸²è¾“å…¥ â†’ å­—ç¬¦ä¸²è¾“å‡ºâ€æ¨¡å‹ä¸åŒï¼ŒèŠå¤©æ¨¡å‹æ›´è´´è¿‘çœŸå®å¯¹è¯ï¼Œæ”¯æŒè§’è‰²åŒºåˆ†ï¼ˆå¦‚ç³»ç»Ÿã€ç”¨æˆ·ã€åŠ©æ‰‹ï¼‰ï¼Œå¹¶èƒ½å¤„ç†å¤šè½®å¯¹è¯ã€å·¥å…·è°ƒç”¨ç­‰å¤æ‚åœºæ™¯ã€‚

> âœ… æç¤ºï¼šåœ¨ LangChain ä¸­ï¼Œâ€œLLMâ€ å’Œ â€œèŠå¤©æ¨¡å‹â€ å¸¸è¢«äº’æ¢ä½¿ç”¨ï¼Œä½†æŠ€æœ¯ä¸Š **èŠå¤©æ¨¡å‹æ›´ç°ä»£ã€åŠŸèƒ½æ›´ä¸°å¯Œ**ã€‚

##### 2.1.2 æ ¸å¿ƒç‰¹æ€§

LangChain çš„èŠå¤©æ¨¡å‹æ”¯æŒä»¥ä¸‹é«˜çº§åŠŸèƒ½ï¼š

| ç‰¹æ€§                                  | è¯´æ˜                                   |
| ------------------------------------- | -------------------------------------- |
| âœ… **å·¥å…·è°ƒç”¨ï¼ˆTool Callingï¼‰**        | æ¨¡å‹å¯è°ƒç”¨å¤–éƒ¨å‡½æ•°ã€APIã€æ•°æ®åº“ç­‰      |
| âœ… **ç»“æ„åŒ–è¾“å‡ºï¼ˆStructured Outputï¼‰** | å¼ºåˆ¶æ¨¡å‹è¿”å› JSONã€Pydantic æ¨¡å‹ç­‰æ ¼å¼ |
| âœ… **å¤šæ¨¡æ€ï¼ˆMultimodalï¼‰**            | æ”¯æŒå›¾åƒã€éŸ³é¢‘ç­‰éæ–‡æœ¬è¾“å…¥ï¼ˆéƒ¨åˆ†æ¨¡å‹ï¼‰ |
| âœ… **æµå¼è¾“å‡ºï¼ˆStreamingï¼‰**           | å®æ—¶æ¥æ”¶æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ             |
| âœ… **å¼‚æ­¥æ”¯æŒ**                        | æ”¯æŒ `async/await` é«˜æ•ˆå¤„ç†å¹¶å‘è¯·æ±‚    |
| âœ… **ç¼“å­˜ä¸è°ƒè¯•**                      | æ”¯æŒå“åº”ç¼“å­˜ã€LangSmith é›†æˆè°ƒè¯•       |

------

##### 2.1.3 æ”¯æŒçš„æ¨¡å‹æä¾›å•†

LangChain æ”¯æŒå¤šç§ä¸»æµæ¨¡å‹ï¼Œåˆ†ä¸ºä¸¤ç±»ï¼š

| ç±»å‹         | è¯´æ˜               | ç¤ºä¾‹                                      |
| ------------ | ------------------ | ----------------------------------------- |
| **å®˜æ–¹æ¨¡å‹** | å®˜æ–¹ç»´æŠ¤ï¼ŒåŠŸèƒ½å®Œæ•´ | `langchain-openai`, `langchain-anthropic` |
| **ç¤¾åŒºæ¨¡å‹** | ç¤¾åŒºè´¡çŒ®           | `langchain-community` åŒ…ä¸­                |

å¸¸è§æ”¯æŒçš„èŠå¤©æ¨¡å‹ç±»åï¼š

- `ChatOpenAI`ï¼šOpenAI çš„ GPT ç³»åˆ—
- `ChatAnthropic`ï¼šAnthropic çš„ Claude ç³»åˆ—
- `ChatOllama`ï¼šæœ¬åœ°è¿è¡Œçš„ Ollama æ¨¡å‹
- `ChatGoogleVertex`ï¼šGoogle Vertex AI
- `ChatBedrock`ï¼šAmazon Bedrock

> âš ï¸ æ³¨æ„ï¼šç±»å**å¸¦ `Chat` å‰ç¼€**çš„æ‰æ˜¯èŠå¤©æ¨¡å‹æ¥å£ã€‚ä¸å¸¦ `Chat` æˆ–å¸¦ `LLM` åç¼€çš„æ˜¯æ—§ç‰ˆæ¨¡å‹ï¼Œ**ä¸æ¨èä½¿ç”¨**ã€‚

##### 2.1.4 æ ‡å‡†å‚æ•°ï¼ˆStandard Parametersï¼‰

| å‚æ•°           | ç±»å‹            | è¯´æ˜                             |
| -------------- | --------------- | -------------------------------- |
| `model`        | str             | æ¨¡å‹åç§°ï¼Œå¦‚ `"gpt-3.5-turbo"`   |
| `temperature`  | float           | è¾“å‡ºéšæœºæ€§ï¼Œ0ï¼ˆç¡®å®šï¼‰~ 1ï¼ˆéšæœºï¼‰ |
| `max_tokens`   | int             | æœ€å¤§è¾“å‡º token æ•°                |
| `timeout`      | float           | è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰               |
| `stop`         | list[str]       | åœæ­¢ç”Ÿæˆçš„å­—ç¬¦ä¸²åºåˆ—             |
| `max_retries`  | int             | å¤±è´¥åæœ€å¤§é‡è¯•æ¬¡æ•°               |
| `api_key`      | str             | è®¤è¯å¯†é’¥                         |
| `base_url`     | str             | è‡ªå®šä¹‰ API åœ°å€ï¼ˆå¦‚æœ¬åœ°éƒ¨ç½²ï¼‰    |
| `rate_limiter` | BaseRateLimiter | é€Ÿç‡é™åˆ¶å™¨ï¼Œé˜²é™æµ               |

##### 2.1.5 æ ¸å¿ƒæ–¹æ³•

| æ–¹æ³•                              | è¯´æ˜                       |
| --------------------------------- | -------------------------- |
| `.invoke(messages)`               | åŒæ­¥è°ƒç”¨ï¼Œè¿”å›å•æ¡æ¶ˆæ¯     |
| `.stream(messages)`               | æµå¼è¾“å‡ºï¼Œé€å­—è¿”å›ç”Ÿæˆå†…å®¹ |
| `.batch(messages_list)`           | æ‰¹é‡å¤„ç†å¤šä¸ªè¯·æ±‚           |
| `.bind_tools(tools)`              | ç»‘å®šå·¥å…·ä¾›æ¨¡å‹è°ƒç”¨         |
| `.with_structured_output(schema)` | å¼ºåˆ¶è¿”å›ç»“æ„åŒ–æ•°æ®         |

##### 2.1.6 ç¤ºä¾‹

ç›´æ¥è°ƒç”¨

```
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.llms.ollama import Ollama

# åˆå§‹åŒ–æ¨¡å‹
chat  = Ollama(
    model="deepseek-r1:1.5b",  # ä½¿ç”¨çš„æ¨¡å‹åç§°
    base_url="http://localhost:11434",  # Ollama æœåŠ¡åœ°å€
    temperature=0.7  # å¯é€‰å‚æ•°
)

# æ„é€ æ¶ˆæ¯
messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚"),
    HumanMessage(content="ä¸­å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ")
]

# è°ƒç”¨æ¨¡å‹
response = chat.invoke(messages)
print(response)
# è¾“å‡ºï¼šä¸­å›½çš„é¦–éƒ½æ˜¯åŒ—äº¬ã€‚
```

è°ƒç”¨å·¥å…·

```
from langchain_core.messages import HumanMessage
from langchain_ollama import ChatOllama  # æ³¨æ„ï¼šæ˜¯ ChatOllama
from langchain_core.tools import tool

# å®šä¹‰å·¥å…·
@tool
def get_weather(location: str) -> str:
    """æŸ¥è¯¢æŸä¸ªåŸå¸‚çš„å¤©æ°”"""
    return f"{location} å½“å‰å¤©æ°”ï¼šæ™´ï¼Œ25Â°C"

# åˆå§‹åŒ–æ¨¡å‹ï¼ˆä½¿ç”¨ ChatOllamaï¼‰
chat = ChatOllama(
    model="qwen3:1.7b",  # æ¨èä½¿ç”¨æ”¯æŒå·¥å…·è°ƒç”¨çš„æ¨¡å‹ï¼Œå¦‚ qwen:14b-chat, dolphin-llama3 ç­‰
    base_url="http://localhost:11434",
    temperature=0.3,
).bind_tools([get_weather])

# æ„é€ æ¶ˆæ¯
messages = [HumanMessage(content="åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")]

# è°ƒç”¨æ¨¡å‹
ai_msg = chat.invoke(messages)

# è¾“å‡ºç»“æœ
print(ai_msg)
print("\nå·¥å…·è°ƒç”¨ä¿¡æ¯ï¼š")
print(ai_msg.tool_calls)
```



#### 2.2  æ¶ˆæ¯ç³»ç»Ÿ

##### 2.2.1 æ¶ˆæ¯çš„åŸºæœ¬ç»„æˆ

æ¯æ¡æ¶ˆæ¯é€šå¸¸åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š

1. **è§’è‰²**ï¼ˆRoleï¼‰ï¼šå®šä¹‰æ¶ˆæ¯çš„ç±»å‹å’Œæ¥æºã€‚
2. **å†…å®¹**ï¼ˆContentï¼‰ï¼šæ¶ˆæ¯çš„å®é™…å†…å®¹ï¼Œå¯ä»¥æ˜¯æ–‡æœ¬æˆ–ç»“æ„åŒ–æ•°æ®ã€‚
3. **å…ƒæ•°æ®**ï¼ˆMetadataï¼‰ï¼šå¯é€‰çš„é™„åŠ ä¿¡æ¯ï¼Œå¦‚ IDã€åç§°ã€token ä½¿ç”¨é‡ç­‰ã€‚

##### 2.2.2 æ¶ˆæ¯è§’è‰²ï¼ˆRolesï¼‰

| è§’è‰²               | æè¿°                                                         |
| ------------------ | ------------------------------------------------------------ |
| `system`           | ç”¨äºå¼•å¯¼æ¨¡å‹è¡Œä¸ºï¼Œè®¾å®šå¯¹è¯ä¸Šä¸‹æ–‡æˆ–è§’è‰²ï¼ˆå¦‚â€œä½ æ˜¯ä¸€ä¸ªçƒ¹é¥ªä¸“å®¶â€ï¼‰ã€‚å¹¶éæ‰€æœ‰æ¨¡å‹éƒ½ç›´æ¥æ”¯æŒã€‚ |
| `user`             | ç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼Œä»£è¡¨ä¸æ¨¡å‹äº¤äº’çš„ç”¨æˆ·ã€‚                       |
| `assistant`        | æ¨¡å‹ç”Ÿæˆçš„å“åº”ï¼Œå¯èƒ½åŒ…å«æ–‡æœ¬æˆ–å·¥å…·è°ƒç”¨è¯·æ±‚ã€‚                 |
| `tool`             | å·¥å…·è°ƒç”¨çš„ç»“æœè¿”å›ç»™æ¨¡å‹çš„æ¶ˆæ¯ã€‚                             |
| `function`ï¼ˆæ—§ç‰ˆï¼‰ | å¯¹åº” OpenAI çš„æ—§ç‰ˆå‡½æ•°è°ƒç”¨ APIï¼Œ**åº”ä½¿ç”¨ `tool` æ›¿ä»£**ã€‚     |

------

##### 2.2.3 ä¸»è¦æ¶ˆæ¯ç±»å‹

LangChain æä¾›äº†å¤šç§æ¶ˆæ¯ç±»ï¼Œå‡ç»§æ‰¿è‡ª `BaseMessage`ã€‚

###### 1. `SystemMessage` - ç³»ç»Ÿæ¶ˆæ¯

ç”¨äºè®¾å®šå¯¹è¯çš„åˆå§‹ä¸Šä¸‹æ–‡æˆ–è¡Œä¸ºå‡†åˆ™ã€‚

```
from langchain_core.messages import SystemMessage

system_msg = SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¨å¸ˆï¼Œæ“…é•¿è§£é‡Šçƒ¹é¥ªæŠ€å·§ã€‚")
```

> **æ³¨æ„**ï¼šä¸åŒæ¨¡å‹å¯¹ç³»ç»Ÿæ¶ˆæ¯çš„æ”¯æŒæ–¹å¼ä¸åŒï¼š
>
> - æœ‰äº›é€šè¿‡ `role="system"` ç›´æ¥æ”¯æŒã€‚
> - æœ‰äº›é€šè¿‡ä¸“ç”¨ API å‚æ•°ä¼ é€’ã€‚
> - ä¸æ”¯æŒçš„æ¨¡å‹ï¼ŒLangChain ä¼šå°è¯•å°†å…¶åˆå¹¶åˆ° `HumanMessage` ä¸­ã€‚

------

###### 2. `HumanMessage` - ç”¨æˆ·æ¶ˆæ¯

ä»£è¡¨ç”¨æˆ·çš„è¾“å…¥ã€‚

```
from langchain_core.messages import HumanMessage

human_msg = HumanMessage(content="å¦‚ä½•ç…®æ„å¤§åˆ©é¢ï¼Ÿ")
```

> **æç¤º**ï¼šå½“ç›´æ¥ä¼ å…¥å­—ç¬¦ä¸²æ—¶ï¼ŒLangChain ä¼šè‡ªåŠ¨å°†å…¶è½¬æ¢ä¸º `HumanMessage`ï¼š
>
> Pythonæ·±è‰²ç‰ˆæœ¬
>
> ```
> model.invoke("Hello, how are you?")
> # ç­‰ä»·äº model.invoke([HumanMessage(content="Hello, how are you?")])
> ```

------

###### 3. `AIMessage` - åŠ©æ‰‹æ¶ˆæ¯

ä»£è¡¨æ¨¡å‹çš„å“åº”ï¼Œå¯èƒ½åŒ…å«æ–‡æœ¬æˆ–å·¥å…·è°ƒç”¨ã€‚

```
from langchain_core.messages import HumanMessage, AIMessage

# è°ƒç”¨æ¨¡å‹
ai_message = model.invoke([HumanMessage(content="è®²ä¸ªç¬‘è¯å§")])
print(ai_message.content)
# è¾“å‡ºç¤ºä¾‹ï¼š "å½“ç„¶ï¼ç¨»è‰äººä¸ºä»€ä¹ˆè·å¥–ï¼Ÿå› ä¸ºå®ƒåœ¨è‡ªå·±çš„é¢†åŸŸè¡¨ç°å‡ºè‰²ï¼"
```

**`AIMessage` çš„ä¸»è¦å±æ€§ï¼š**

| å±æ€§                 | ç±»å‹   | æè¿°                                         |
| -------------------- | ------ | -------------------------------------------- |
| `content`            | åŸå§‹   | å“åº”å†…å®¹ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸åˆ—è¡¨ï¼ˆå¤šæ¨¡æ€ï¼‰ã€‚ |
| `tool_calls`         | æ ‡å‡†åŒ– | å·¥å…·è°ƒç”¨è¯·æ±‚åˆ—è¡¨ã€‚                           |
| `invalid_tool_calls` | æ ‡å‡†åŒ– | è§£æå¤±è´¥çš„å·¥å…·è°ƒç”¨ã€‚                         |
| `usage_metadata`     | æ ‡å‡†åŒ– | token ä½¿ç”¨ç»Ÿè®¡ã€‚                             |
| `id`                 | æ ‡å‡†åŒ– | æ¶ˆæ¯å”¯ä¸€æ ‡è¯†ç¬¦ã€‚                             |
| `response_metadata`  | åŸå§‹   | æ¨¡å‹ç‰¹å®šçš„å“åº”å…ƒæ•°æ®ã€‚                       |

------

###### 4. `AIMessageChunk` - æµå¼å“åº”å—

ç”¨äºæµå¼ä¼ è¾“æ¨¡å‹å“åº”ï¼Œç”¨æˆ·å¯ä»¥å®æ—¶çœ‹åˆ°è¾“å‡ºã€‚

```
# æµå¼è¾“å‡º
for chunk in model.stream([HumanMessage("å¤©ç©ºæ˜¯ä»€ä¹ˆé¢œè‰²ï¼Ÿ")]):
    print(chunk.content, end="", flush=True)
```

> `AIMessageChunk` æ”¯æŒ `+` æ“ä½œç¬¦åˆå¹¶ä¸ºå®Œæ•´çš„ `AIMessage`ï¼š
>
> ```
> full_message = chunk1 + chunk2 + chunk3
> ```



###### 5. `ToolMessage` - å·¥å…·æ¶ˆæ¯

å°†å·¥å…·è°ƒç”¨ç»“æœè¿”å›ç»™æ¨¡å‹ã€‚

```
from langchain_core.messages import ToolMessage

tool_response = ToolMessage(
    content="2025å¹´9æœˆ17æ—¥çš„å¤©æ°”ï¼šæ™´ï¼Œæ°”æ¸©25Â°C",
    tool_call_id="call_abc123"  # å¿…é¡»åŒ¹é…ä¹‹å‰çš„ tool_call_id
)
```



###### 6. `RemoveMessage`ï¼ˆç‰¹æ®Šç±»å‹ï¼‰

ä¸å¯¹åº”ä»»ä½•è§’è‰²ï¼Œç”¨äºåœ¨ **LangGraph** ä¸­ç®¡ç†èŠå¤©å†å²ï¼Œä¾‹å¦‚åˆ é™¤æ—§æ¶ˆæ¯ä»¥æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦ã€‚

##### 2.2.4 å¤šæ¨¡æ€æ¶ˆæ¯æ”¯æŒ

æ¶ˆæ¯å†…å®¹å¯ä»¥æ˜¯ï¼š

- **çº¯æ–‡æœ¬**
- **å­—å…¸åˆ—è¡¨**ï¼ˆç”¨äºå›¾åƒã€éŸ³é¢‘ç­‰ï¼‰

```
# ç¤ºä¾‹ï¼šåŒ…å«å›¾åƒçš„å¤šæ¨¡æ€è¾“å…¥ï¼ˆå…·ä½“æ ¼å¼ä¾èµ–æ¨¡å‹ï¼‰
human_msg = HumanMessage(
    content=[
        {"type": "text", "text": "æè¿°è¿™å¼ å›¾ç‰‡"},
        {"type": "image_url", "image_url": "https://example.com/image.jpg"}
    ]
)
```

> **æ³¨æ„**ï¼šå¤šæ¨¡æ€æ”¯æŒå› æ¨¡å‹è€Œå¼‚ï¼Œç›®å‰ä»å¤„äºå‘å±•é˜¶æ®µã€‚

##### 2.3.5 å¯¹è¯ç»“æ„ç¤ºä¾‹

ä¸€ä¸ªå…¸å‹çš„å¯¹è¯åº”éµå¾ªåˆç†çš„ç»“æ„ï¼š

```
from langchain_core.messages import HumanMessage, AIMessage

conversation = [
    HumanMessage(content="ä½ å¥½ï¼Œä½ æ€ä¹ˆæ ·ï¼Ÿ"),
    AIMessage(content="æˆ‘å¾ˆå¥½ï¼Œè°¢è°¢ï¼"),
    HumanMessage(content="ä½ èƒ½ç»™æˆ‘è®²ä¸ªç¬‘è¯å—ï¼Ÿ"),
    AIMessage(content="å½“ç„¶ï¼ä¸ºä»€ä¹ˆç¨‹åºå‘˜åˆ†ä¸æ¸…ä¸‡åœ£èŠ‚å’Œåœ£è¯èŠ‚ï¼Ÿå› ä¸º Oct 31 == Dec 25ï¼")
]
```

##### 2.3.6 æ€»ç»“

LangChain çš„æ¶ˆæ¯ç³»ç»Ÿæä¾›äº†ä¸€ä¸ªå¼ºå¤§ä¸”çµæ´»çš„æŠ½è±¡å±‚ï¼Œä½¿å¼€å‘è€…èƒ½å¤Ÿï¼š

- ä½¿ç”¨ç»Ÿä¸€çš„ API ä¸å¤šç§èŠå¤©æ¨¡å‹äº¤äº’ã€‚
- æ„å»ºå¤æ‚çš„å¯¹è¯æµç¨‹ï¼ŒåŒ…æ‹¬å·¥å…·è°ƒç”¨å’Œæµå¼å“åº”ã€‚
- æ”¯æŒå¤šæ¨¡æ€è¾“å…¥å’Œé«˜çº§ä¸Šä¸‹æ–‡ç®¡ç†ã€‚
- æ— ç¼é›†æˆ OpenAI å…¼å®¹æ ¼å¼ã€‚

é€šè¿‡åˆç†ä½¿ç”¨ `SystemMessage`ã€`HumanMessage`ã€`AIMessage` å’Œ `ToolMessage`ï¼Œå¯ä»¥æ„å»ºå‡ºåŠŸèƒ½ä¸°å¯Œã€å“åº”è¿…é€Ÿçš„å¯¹è¯å¼ AI åº”ç”¨ã€‚

##### 2.3.7 ç¤ºä¾‹

```
from langchain_community.chat_models import ChatOllama
from langchain_core.messages import (
    SystemMessage,
    HumanMessage,
    AIMessage,
    ToolMessage,
    AIMessageChunk,
)
import json

# åˆå§‹åŒ–æœ¬åœ° ChatOllama æ¨¡å‹
# ä½¿ç”¨ llama3.1 æˆ–å…¶ä»–æ”¯æŒå¯¹è¯çš„æ¨¡å‹
model = ChatOllama(
    model="qwen3:1.7b",  # ç¡®ä¿è¯¥æ¨¡å‹å·²é€šè¿‡ ollama pull ä¸‹è½½
    temperature=0.7,
    base_url="http://localhost:11434",  # é»˜è®¤ Ollama åœ°å€
)

# ==========================
# 1. SystemMessage: è®¾å®šè§’è‰²
# ==========================
system_message = SystemMessage(
    content="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„çƒ¹é¥ªåŠ©æ‰‹ï¼Œæ“…é•¿æä¾›ç®€å•æ˜“æ‡‚çš„é£Ÿè°±å’Œçƒ¹é¥ªæŠ€å·§ã€‚"
)

# ==========================
# 2. HumanMessage: ç”¨æˆ·æé—®
# ==========================
human_message = HumanMessage(
    content="æˆ‘æƒ³åšç•ªèŒ„ç‚’è›‹ï¼Œèƒ½å‘Šè¯‰æˆ‘æ­¥éª¤å—ï¼Ÿ"
)

print("ğŸ’¬ ç”¨æˆ·: æˆ‘æƒ³åšç•ªèŒ„ç‚’è›‹ï¼Œèƒ½å‘Šè¯‰æˆ‘æ­¥éª¤å—ï¼Ÿ\n")
print("ğŸ³ åŠ©æ‰‹ (æµå¼è¾“å‡º): ", end="", flush=True)

# ==========================
# 3. AIMessageChunk: æµå¼è¾“å‡ºå“åº”
# ==========================
full_response = ""
for chunk in model.stream([system_message, human_message]):
    if isinstance(chunk, AIMessageChunk):
        content = chunk.content
        print(content, end="", flush=True)
        full_response += content

print("\n")

# å°†æµå¼è¾“å‡ºåˆå¹¶ä¸ºå®Œæ•´ AIMessage
ai_message = AIMessage(content=full_response)

# ==========================
# 4. æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨ï¼šæŸ¥è¯¢é£Ÿæåº“å­˜
# ==========================
# å‡è®¾æ¨¡å‹å†³å®šè°ƒç”¨ä¸€ä¸ªâ€œæ£€æŸ¥åº“å­˜â€å·¥å…·
# æ³¨æ„ï¼šOllama æœ¬èº«ä¸åŸç”Ÿæ”¯æŒç»“æ„åŒ– tool_callï¼Œä½†æˆ‘ä»¬å¯ä»¥æ¨¡æ‹Ÿ

# æ‰‹åŠ¨æ„é€ ä¸€ä¸ªå·¥å…·è°ƒç”¨è¯·æ±‚ï¼ˆå®é™…ä¸­å¯é€šè¿‡æç¤ºå·¥ç¨‹è§¦å‘ï¼‰
# è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿæ¨¡å‹è¿”å›äº†ä¸€ä¸ªéœ€è¦è°ƒç”¨å·¥å…·çš„å“åº”

# é‡æ–°æé—®ï¼Œå¼•å¯¼æ¨¡å‹â€œè°ƒç”¨å·¥å…·â€
tool_prompt = [
    system_message,
    HumanMessage(content="æˆ‘æœ‰é¸¡è›‹ï¼Œä½†ä¸ç¡®å®šæœ‰æ²¡æœ‰ç•ªèŒ„ã€‚è¯·å¸®æˆ‘æ£€æŸ¥ç•ªèŒ„åº“å­˜ã€‚"),
]

print("\nğŸ” æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨æµç¨‹...")

# å¼ºåˆ¶è®©æ¨¡å‹â€œæƒ³è±¡â€å®ƒè°ƒç”¨äº†å·¥å…·
tool_simulation_prompt = tool_prompt + [
    AIMessage(content="æˆ‘å°†è°ƒç”¨ 'check_inventory' å·¥å…·æ¥æ£€æŸ¥ç•ªèŒ„åº“å­˜ã€‚"),
]

# æ¨¡æ‹Ÿå·¥å…·è¿”å›ç»“æœ
tool_result = ToolMessage(
    content=json.dumps({"item": "tomato", "in_stock": True, "quantity": 3}),
    tool_call_id="call_tomato_check_123",  # åŒ¹é…å‡è®¾çš„è°ƒç”¨ ID
    name="check_inventory"  # å¯é€‰ï¼šå·¥å…·åç§°
)

# å°†å·¥å…·ç»“æœä¼ å›æ¨¡å‹ï¼Œè®©å…¶ç”Ÿæˆæœ€ç»ˆå›ç­”
final_response = model.invoke(
    tool_simulation_prompt + [tool_result]
)

print(f"\nğŸ“¦ å·¥å…·è¿”å›: {{'item': 'tomato', 'in_stock': True, 'quantity': 3}}")
print(f"ğŸ¤– åŠ©æ‰‹æœ€ç»ˆå›å¤: {final_response.content}")
```



#### 2.3 æç¤ºæ¨¡æ¿ï¼ˆPrompt Templates

##### 2.3.1 æ¦‚è¿°

**æç¤ºæ¨¡æ¿**ï¼ˆPrompt Templatesï¼‰æ˜¯ LangChain æ¡†æ¶ä¸­çš„æ ¸å¿ƒç»„ä»¶ä¹‹ä¸€ï¼Œç”¨äºå°†ç”¨æˆ·è¾“å…¥å’Œå‚æ•°åŠ¨æ€åœ°è½¬æ¢ä¸ºè¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥ç†è§£çš„æŒ‡ä»¤ã€‚å®ƒå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°ç†è§£ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆæ›´ç›¸å…³ã€è¿è´¯çš„è¾“å‡ºã€‚

æç¤ºæ¨¡æ¿æ¥æ”¶ä¸€ä¸ªå­—å…¸ä½œä¸ºè¾“å…¥ï¼ˆé”®å¯¹åº”æ¨¡æ¿ä¸­çš„å˜é‡ï¼‰ï¼Œè¾“å‡ºä¸€ä¸ª `PromptValue` å¯¹è±¡ï¼Œè¯¥å¯¹è±¡å¯è¢«ä¼ é€’ç»™ LLM æˆ–èŠå¤©æ¨¡å‹ï¼Œä¹Ÿå¯è½¬æ¢ä¸ºå­—ç¬¦ä¸²æˆ–æ¶ˆæ¯åˆ—è¡¨ã€‚

##### 2.3.2 ä¸»è¦ç±»å‹

LangChain æä¾›äº†ä¸¤ç§ä¸»è¦ç±»å‹çš„æç¤ºæ¨¡æ¿ï¼š

###### 1. `PromptTemplate` - å­—ç¬¦ä¸²æç¤ºæ¨¡æ¿

é€‚ç”¨äºç®€å•çš„æ–‡æœ¬è¾“å…¥åœºæ™¯ï¼Œç”¨äºæ ¼å¼åŒ–å•ä¸ªå­—ç¬¦ä¸²ã€‚

```
from langchain_core.prompts import PromptTemplate

# å®šä¹‰æ¨¡æ¿
prompt_template = PromptTemplate.from_template(
    "è®²ä¸€ä¸ªå…³äº {topic} çš„ç¬‘è¯ã€‚"
)

# è°ƒç”¨æ¨¡æ¿
result = prompt_template.invoke({"topic": "çŒ«"})
print(result.text)
# è¾“å‡ºç¤ºä¾‹ï¼š "ä¸ºä»€ä¹ˆçŒ«å–œæ¬¢ååœ¨é”®ç›˜ä¸Šï¼Ÿå› ä¸ºå®ƒä»¬æƒ³æ§åˆ¶ä½ çš„ç”Ÿæ´»ï¼"
```

> **API å‚è€ƒ**ï¼šPromptTemplate

###### 2. `ChatPromptTemplate` - èŠå¤©æç¤ºæ¨¡æ¿

ç”¨äºæ„å»º**æ¶ˆæ¯åˆ—è¡¨**ï¼Œé€‚ç”¨äºä¸èŠå¤©æ¨¡å‹äº¤äº’çš„å¤æ‚å¯¹è¯åœºæ™¯ã€‚æ¨¡æ¿ç”±å¤šä¸ªæ¶ˆæ¯å¯¹ç»„æˆï¼Œæ”¯æŒç³»ç»Ÿæ¶ˆæ¯ã€ç”¨æˆ·æ¶ˆæ¯ç­‰ã€‚

```
from langchain_core.prompts import ChatPromptTemplate

# å®šä¹‰èŠå¤©æ¨¡æ¿
prompt_template = ChatPromptTemplate([
    ("system", "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚"),
    ("user", "è®²ä¸€ä¸ªå…³äº {topic} çš„ç¬‘è¯ã€‚")
])

# è°ƒç”¨æ¨¡æ¿
prompt_value = prompt_template.invoke({"topic": "ç¨‹åºå‘˜"})
print(prompt_value.to_messages())
```

> **è¾“å‡º**ï¼š
>
> ```
> [SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚'),
>  HumanMessage(content='è®²ä¸€ä¸ªå…³äº ç¨‹åºå‘˜ çš„ç¬‘è¯ã€‚')]
> ```

> **API å‚è€ƒ**ï¼šChatPromptTemplate

###### 3. `MessagesPlaceholder` - æ¶ˆæ¯å ä½ç¬¦

ç”¨äºåœ¨æ¨¡æ¿ä¸­æ’å…¥**åŠ¨æ€çš„æ¶ˆæ¯åˆ—è¡¨**ï¼Œä¾‹å¦‚èŠå¤©å†å²ã€‚è¿™æ˜¯å®ç°è®°å¿†åŠŸèƒ½çš„å…³é”®ã€‚

```
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage

# æ¨¡æ¿åŒ…å«ç³»ç»Ÿæ¶ˆæ¯ + åŠ¨æ€æ¶ˆæ¯å ä½ç¬¦
prompt_template = ChatPromptTemplate([
    ("system", "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚"),
    MessagesPlaceholder("history"),  # å†å²æ¶ˆæ¯æ’å…¥æ­¤å¤„
    ("user", "{input}")
])

# æ¨¡æ‹ŸèŠå¤©å†å²
history = [
    HumanMessage(content="ä½ å¥½ï¼"),
    AIMessage(content="ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼Ÿ")
]

# ç”Ÿæˆæœ€ç»ˆæç¤º
prompt_value = prompt_template.invoke({
    "history": history,
    "input": "ä½ èƒ½ç»™æˆ‘è®²ä¸ªç¬‘è¯å—ï¼Ÿ"
})

print(prompt_value.to_messages())
```

> è¿™å°†ç”Ÿæˆä¸€ä¸ªåŒ…å«ç³»ç»Ÿæ¶ˆæ¯ã€å†å²æ¶ˆæ¯å’Œæ–°ç”¨æˆ·è¾“å…¥çš„å®Œæ•´æ¶ˆæ¯åºåˆ—ã€‚

###### æ›¿ä»£å†™æ³•ï¼šä½¿ç”¨ `placeholder`

ä½ ä¹Ÿå¯ä»¥ä¸æ˜¾å¼ä½¿ç”¨ `MessagesPlaceholder`ï¼Œè€Œæ˜¯é€šè¿‡å­—ç¬¦ä¸²å ä½ç¬¦æ–¹å¼ï¼š

Pythonæ·±è‰²ç‰ˆæœ¬

```
prompt_template = ChatPromptTemplate([
    ("system", "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚"),
    ("placeholder", "{history}"),  # ä½¿ç”¨å­—ç¬¦ä¸²å ä½ç¬¦
    ("user", "{input}")
])
```

##### 2.3.3 æ ¸å¿ƒåŠŸèƒ½æ€»ç»“

| åŠŸèƒ½           | è¯´æ˜                                      |
| -------------- | ----------------------------------------- |
| **å˜é‡å¡«å……**   | ä½¿ç”¨ `{variable}` è¯­æ³•åŠ¨æ€æ’å…¥å†…å®¹        |
| **æ¶ˆæ¯ç»“æ„åŒ–** | æ”¯æŒç³»ç»Ÿã€ç”¨æˆ·ã€åŠ©æ‰‹ç­‰è§’è‰²çš„æ¶ˆæ¯ç»„ç»‡      |
| **å†å²é›†æˆ**   | é€šè¿‡ `MessagesPlaceholder` æ’å…¥èŠå¤©å†å²   |
| **ç»Ÿä¸€è¾“å‡º**   | è¾“å‡º `PromptValue`ï¼Œå…¼å®¹ LLM å’Œ ChatModel |
| **çµæ´»æ‰©å±•**   | å¯ç»„åˆå¤šä¸ªæ¨¡æ¿ã€æ”¯æŒéƒ¨åˆ†æ ¼å¼åŒ–ç­‰          |

#### 2.4 è¡¨è¾¾å¼è¯­è¨€ï¼ˆLCELï¼‰

##### 2.4.1 æ¦‚è¿°

**LangChain è¡¨è¾¾å¼è¯­è¨€**ï¼ˆLangChain Expression Languageï¼Œç®€ç§° **LCEL**ï¼‰æ˜¯ LangChain çš„æ ¸å¿ƒç¼–ç¨‹èŒƒå¼ï¼Œç”¨äºä»¥å£°æ˜å¼ã€å¯ç»„åˆçš„æ–¹å¼æ„å»ºå¯è¿è¡Œï¼ˆRunnableï¼‰çš„é“¾ï¼ˆChainï¼‰ã€‚å®ƒå…è®¸å¼€å‘è€…å°†å°å‹ç»„ä»¶ï¼ˆå¦‚æç¤ºæ¨¡æ¿ã€æ¨¡å‹ã€è§£æå™¨ç­‰ï¼‰åƒç§¯æœ¨ä¸€æ ·è¿æ¥èµ·æ¥ï¼Œå½¢æˆå¤æ‚çš„åº”ç”¨æµç¨‹ã€‚

LCEL ä¸ä»…æå‡äº†ä»£ç çš„å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§ï¼Œè¿˜ä¸ºç”Ÿäº§ç¯å¢ƒæä¾›äº†å…³é”®ä¼˜åŠ¿ï¼š**è‡ªåŠ¨ä¼˜åŒ–æ‰§è¡Œã€å¼‚æ­¥æ”¯æŒã€æµå¼ä¼ è¾“ã€LangSmith è¿½è¸ªå’Œæ— ç¼éƒ¨ç½²èƒ½åŠ›**ã€‚

##### 2.4.2 æ ¸å¿ƒç†å¿µ

- **å£°æ˜å¼ç¼–ç¨‹**ï¼šä½ æè¿°â€œè¦åšä»€ä¹ˆâ€ï¼Œè€Œä¸æ˜¯â€œå¦‚ä½•åšâ€ã€‚LangChain è´Ÿè´£ä¼˜åŒ–è¿è¡Œæ—¶æ‰§è¡Œã€‚
- **æ‰€æœ‰ç»„ä»¶éƒ½æ˜¯ `Runnable`**ï¼šæ— è®ºæ˜¯æç¤ºã€æ¨¡å‹è¿˜æ˜¯è‡ªå®šä¹‰å‡½æ•°ï¼Œéƒ½å®ç°äº†ç»Ÿä¸€çš„ `Runnable` æ¥å£ã€‚
- **é“¾å³ Runnable**ï¼šä½¿ç”¨ LCEL æ„å»ºçš„â€œé“¾â€æœ¬èº«ä¹Ÿæ˜¯ä¸€ä¸ª `Runnable`ï¼Œå¯ä»¥åµŒå¥—ã€å¤ç”¨å’Œéƒ¨ç½²ã€‚

> âœ… ç®€å•è¯´ï¼šLCEL æ˜¯ LangChain çš„â€œèƒ¶æ°´è¯­è¨€â€ï¼Œè®©ä½ è½»æ¾æ‹¼æ¥ AI åº”ç”¨çš„å„ä¸ªéƒ¨åˆ†ã€‚

##### 2.4.3 æ ¸å¿ƒç»„åˆåŸè¯­

LCEL æä¾›äº†ä¸¤ä¸ªåŸºæœ¬çš„ç»„åˆæ–¹å¼æ¥æ„å»ºé“¾ï¼š

###### 1. `RunnableSequence` - é¡ºåºæ‰§è¡Œ

å°†å¤šä¸ªç»„ä»¶æŒ‰é¡ºåºé“¾æ¥ï¼Œå‰ä¸€ä¸ªçš„è¾“å‡ºä½œä¸ºåä¸€ä¸ªçš„è¾“å…¥ã€‚

```
from langchain_core.runnables import RunnableSequence
from langchain_core.prompts import PromptTemplate
from langchain_community.chat_models import ChatOllama
from langchain_core.output_parsers import StrOutputParser

# å®šä¹‰ç»„ä»¶
prompt = PromptTemplate.from_template("è®²ä¸€ä¸ªå…³äº {topic} çš„ç¬‘è¯ã€‚")
model = ChatOllama(model="llama3.1", base_url="http://localhost:11434")
parser = StrOutputParser()

# æ–¹æ³•1ï¼šä½¿ç”¨ RunnableSequence
chain = RunnableSequence([prompt, model, parser])

# è°ƒç”¨
result = chain.invoke({"topic": "çŒ«"})
print(result)
```

------

###### 2. `RunnableParallel` - å¹¶è¡Œæ‰§è¡Œ

å¹¶å‘è¿è¡Œå¤šä¸ªç»„ä»¶ï¼Œè¾“å…¥ç›¸åŒï¼Œè¾“å‡ºåˆå¹¶ä¸ºå­—å…¸ã€‚

```
from langchain_core.runnables import RunnableParallel

# å¹¶è¡Œç”Ÿæˆä¸¤ä¸ªä¸åŒä¸»é¢˜çš„ç¬‘è¯
parallel_chain = RunnableParallel({
    "joke_about_cats": prompt | model | parser,
    "joke_about_dogs": prompt | model | parser
})

result = parallel_chain.invoke({"topic": "çŒ«"})  # æ³¨æ„ï¼šè¿™é‡Œ topic åªå½±å“ cats
print(result)
# è¾“å‡ºç¤ºä¾‹ï¼š {'joke_about_cats': '...', 'joke_about_dogs': '...'}
```

------

###### ç®€æ´è¯­æ³•ï¼š`|` è¿ç®—ç¬¦

LCEL é‡è½½äº† `|` è¿ç®—ç¬¦ï¼Œä½¿é“¾çš„å†™æ³•æ›´ç®€æ´ç›´è§‚ã€‚

```
# æ¨èå†™æ³•ï¼šä½¿ç”¨ | è¿ç®—ç¬¦
chain = prompt | model | parser

# è°ƒç”¨
result = chain.invoke({"topic": "ç¨‹åºå‘˜"})
print(result)
```

è¿™ç­‰ä»·äºï¼š

```
chain = RunnableSequence([prompt, model, parser])
```

> ğŸ’¡ ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ `.pipe()` æ–¹æ³•ï¼Œæ•ˆæœç›¸åŒï¼š`prompt.pipe(model).pipe(parser)`

##### 2.4.4 è‡ªåŠ¨ç±»å‹è½¬æ¢ï¼ˆType Coercionï¼‰

LCEL ä¼šè‡ªåŠ¨å°†æŸäº› Python ç±»å‹è½¬æ¢ä¸º `Runnable`ï¼š

| åŸå§‹ç±»å‹               | è‡ªåŠ¨è½¬æ¢ä¸º         |
| ---------------------- | ------------------ |
| å­—å…¸ `{}`              | `RunnableParallel` |
| å‡½æ•° `def` æˆ– `lambda` | `RunnableLambda`   |

###### å­—å…¸ â†’ RunnableParallel

```
# å­—å…¸ä¼šè‡ªåŠ¨è½¬ä¸ºå¹¶è¡Œæ‰§è¡Œ
chain = {
    "original": lambda x: x,
    "joke": prompt | model | parser
} | StrOutputParser()  # åç»­å¤„ç†
```

###### å‡½æ•° â†’ RunnableLambda

```
# å‡½æ•°è‡ªåŠ¨è½¬ä¸º Runnable
chain = (lambda x: x.upper()) | model
```

> âš ï¸ æ³¨æ„ï¼šåŸå§‹å­—å…¸æˆ–å‡½æ•°ä¸èƒ½ç›´æ¥è°ƒç”¨ `.invoke()`ï¼Œåªæœ‰åœ¨ LCEL è¡¨è¾¾å¼ä¸­æ‰ä¼šè¢«è½¬æ¢ã€‚

##### 2.4.5 LCEL çš„æ ¸å¿ƒä¼˜åŠ¿

| ä¼˜åŠ¿                     | è¯´æ˜                                             |
| ------------------------ | ------------------------------------------------ |
| âœ… **å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–**       | `RunnableParallel` è‡ªåŠ¨å¹¶å‘æ‰§è¡Œï¼Œå‡å°‘å»¶è¿Ÿã€‚      |
| âœ… **å¼‚æ­¥æ”¯æŒ**           | æ‰€æœ‰é“¾å¤©ç„¶æ”¯æŒ `ainvoke`, `astream` ç­‰å¼‚æ­¥æ–¹æ³•ã€‚ |
| âœ… **æµå¼ä¼ è¾“**           | æ”¯æŒ `stream()` å®æ—¶è¾“å‡ºï¼Œä¼˜åŒ–é¦– token æ—¶é—´ã€‚    |
| âœ… **LangSmith è‡ªåŠ¨è¿½è¸ª** | æ‰€æœ‰æ­¥éª¤è‡ªåŠ¨è®°å½•ï¼Œä¾¿äºè°ƒè¯•å’Œç›‘æ§ã€‚               |
| âœ… **æ ‡å‡† API**           | æ‰€æœ‰é“¾éƒ½å®ç° `Runnable` æ¥å£ï¼Œæ˜“äºå¤ç”¨ã€‚         |
| âœ… **å¯éƒ¨ç½²**             | å¯é€šè¿‡ LangServe ç›´æ¥éƒ¨ç½²ä¸º REST APIã€‚           |

##### 2.3.5 æ€»ç»“

**LCEL æ˜¯æ„å»º LangChain åº”ç”¨çš„ç°ä»£æ¨èæ–¹å¼**ï¼Œå®ƒï¼š

- æä¾›äº†ç®€æ´ã€å£°æ˜å¼çš„è¯­æ³•ï¼ˆå¦‚ `prompt \| model \| parser`ï¼‰ã€‚
- è‡ªåŠ¨ä¼˜åŒ–æ‰§è¡Œæ€§èƒ½ï¼ˆå¹¶è¡Œã€æµå¼ã€å¼‚æ­¥ï¼‰ã€‚
- æ·±åº¦é›†æˆå¯è§‚æµ‹æ€§ï¼ˆLangSmithï¼‰å’Œéƒ¨ç½²èƒ½åŠ›ï¼ˆLangServeï¼‰ã€‚
- æ˜¯ä»æ—§ç‰ˆ `LLMChain` ç­‰ç±»è¿ç§»çš„é¦–é€‰æ–¹æ¡ˆã€‚

å¯¹äºå¤§å¤šæ•°ç®€å•åˆ°ä¸­ç­‰å¤æ‚åº¦çš„é“¾ï¼Œ**åº”ä¼˜å…ˆä½¿ç”¨ LCEL**ã€‚å½“åº”ç”¨éœ€è¦å¤æ‚çŠ¶æ€æˆ–æ§åˆ¶æµæ—¶ï¼Œå†è€ƒè™‘å‡çº§åˆ° **LangGraph**ã€‚

#### 2.5 å·¥å…·è°ƒç”¨ï¼ˆTool Callingï¼‰

##### 2.5.1 æ¦‚è¿°

**å·¥å…·è°ƒç”¨**ï¼ˆTool Callingï¼‰æ˜¯ LangChain çš„æ ¸å¿ƒèƒ½åŠ›ä¹‹ä¸€ï¼Œå®ƒå…è®¸è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ä»…ä»…æ˜¯ç”Ÿæˆæ–‡æœ¬ï¼Œè¿˜èƒ½**ç›´æ¥ä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’**ï¼Œä¾‹å¦‚è°ƒç”¨ APIã€æŸ¥è¯¢æ•°æ®åº“ã€æ‰§è¡Œè®¡ç®—ç­‰ã€‚

é€šè¿‡å·¥å…·è°ƒç”¨ï¼ŒAI åº”ç”¨å¯ä»¥å…·å¤‡â€œè¡ŒåŠ¨â€èƒ½åŠ›ï¼Œä»è¢«åŠ¨å›ç­”é—®é¢˜è½¬å˜ä¸º**ä¸»åŠ¨æ‰§è¡Œä»»åŠ¡**ï¼Œæ˜¯æ„å»ºæ™ºèƒ½ Agent çš„å…³é”®æŠ€æœ¯ã€‚

> ğŸ’¡ **æç¤º**ï¼šå·¥å…·è°ƒç”¨æœ‰æ—¶ä¹Ÿè¢«ç§°ä¸ºâ€œå‡½æ•°è°ƒç”¨â€ï¼ˆFunction Callingï¼‰ï¼Œåœ¨ LangChain ä¸­è¿™ä¸¤ä¸ªæœ¯è¯­å¯äº’æ¢ä½¿ç”¨ã€‚

##### 2.5.2 æ ¸å¿ƒæ¦‚å¿µï¼šå·¥å…·è°ƒç”¨çš„å››ä¸ªæ­¥éª¤

å·¥å…·è°ƒç”¨éµå¾ªä¸€ä¸ªæ¸…æ™°çš„å·¥ä½œæµç¨‹ï¼š

###### 1. å·¥å…·åˆ›å»ºï¼ˆTool Creationï¼‰

ä½¿ç”¨ `@tool` è£…é¥°å™¨å°†æ™®é€š Python å‡½æ•°å®šä¹‰ä¸ºä¸€ä¸ªâ€œå·¥å…·â€ã€‚å·¥å…·åŒ…å«å‡½æ•°é€»è¾‘å’Œå…¶è¾“å…¥/è¾“å‡ºçš„ç»“æ„åŒ–æè¿°ã€‚

**åˆ›å»ºä¸€ä¸ªä¹˜æ³•å·¥å…·**

```
from langchain_core.tools import tool

@tool
def multiply(a: int, b: int) -> int:
    """å°† a å’Œ b ç›¸ä¹˜ã€‚"""
    return a * b
```

###### 2. å·¥å…·ç»‘å®šï¼ˆTool Bindingï¼‰

å°†åˆ›å»ºå¥½çš„å·¥å…·ç»‘å®šåˆ°æ”¯æŒå·¥å…·è°ƒç”¨çš„æ¨¡å‹ä¸Šã€‚ä½¿ç”¨ `.bind_tools()` æ–¹æ³•å‘Šè¯‰æ¨¡å‹â€œä½ å¯ä»¥è°ƒç”¨è¿™äº›å·¥å…·â€ã€‚

```
from langchain_community.chat_models import ChatOllama

# åˆå§‹åŒ–æ”¯æŒå·¥å…·è°ƒç”¨çš„æ¨¡å‹ï¼ˆå¦‚ llama3.1ï¼‰
model = ChatOllama(model="llama3.1", base_url="http://localhost:11434")

# ç»‘å®šå·¥å…·
model_with_tools = model.bind_tools([multiply])
```

> âš ï¸ æ³¨æ„ï¼šå¹¶éæ‰€æœ‰æ¨¡å‹éƒ½æ”¯æŒå·¥å…·è°ƒç”¨ã€‚Ollama çš„ `llama3.1` æ”¯æŒåŸºæœ¬çš„å·¥å…·è°ƒç”¨åŠŸèƒ½ã€‚

###### 3. å·¥å…·è°ƒç”¨ï¼ˆTool Callingï¼‰

å‘æ¨¡å‹å‘é€è¯·æ±‚ã€‚æ¨¡å‹ä¼šæ ¹æ®è¾“å…¥å†…å®¹**è‡ªä¸»å†³å®š**æ˜¯å¦è°ƒç”¨å·¥å…·ï¼Œä»¥åŠè°ƒç”¨å“ªä¸ªå·¥å…·ã€‚

```
# ä¸ç›¸å…³çš„è¾“å…¥ â†’ æ¨¡å‹ä¸ä¼šè°ƒç”¨å·¥å…·
result1 = model_with_tools.invoke("ä½ å¥½ï¼")
print(result1.content)  # è¾“å‡ºï¼š "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼Ÿ"

# ç›¸å…³çš„è¾“å…¥ â†’ æ¨¡å‹å†³å®šè°ƒç”¨ multiply å·¥å…·
result2 = model_with_tools.invoke("2 ä¹˜ä»¥ 3 æ˜¯å¤šå°‘ï¼Ÿ")
```

------

###### 4. å·¥å…·æ‰§è¡Œï¼ˆTool Executionï¼‰

å¦‚æœæ¨¡å‹å†³å®šè°ƒç”¨å·¥å…·ï¼Œå…¶å“åº”ä¸­ä¼šåŒ…å« `tool_calls` å±æ€§ã€‚ä½ å¯ä»¥æå–è¿™äº›è°ƒç”¨å¹¶æ‰§è¡Œå¯¹åº”çš„å·¥å…·å‡½æ•°ã€‚

```
# æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨
if result2.tool_calls:
    for tool_call in result2.tool_calls:
        print("æ¨¡å‹è¯·æ±‚è°ƒç”¨å·¥å…·:", tool_call)
        # è¾“å‡ºç¤ºä¾‹ï¼š
        # {'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_abc123', 'type': 'tool_call'}

        # æ‰§è¡Œå·¥å…·
        tool_output = multiply.invoke(tool_call["args"])
        print("å·¥å…·æ‰§è¡Œç»“æœ:", tool_output)  # è¾“å‡ºï¼š6
```

------

##### 2.5.3 å…³é”®ç‰¹æ€§ä¸é«˜çº§ç”¨æ³•

###### âœ… `tool_calls` å±æ€§

æ¨¡å‹å“åº”ï¼ˆ`AIMessage`ï¼‰ä¸­çš„ `tool_calls` æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š

- `name`: å·¥å…·åç§°
- `args`: è°ƒç”¨å‚æ•°ï¼ˆå­—å…¸ï¼‰
- `id`: è°ƒç”¨å”¯ä¸€ ID
- `type`: ç±»å‹ï¼ˆé€šå¸¸æ˜¯ `tool_call`ï¼‰

###### âœ… å¼ºåˆ¶æ¨¡å‹è°ƒç”¨å·¥å…·ï¼ˆ`tool_choice`ï¼‰

ä½ å¯ä»¥å¼ºåˆ¶æ¨¡å‹å¿…é¡»è°ƒç”¨æŸä¸ªç‰¹å®šå·¥å…·ï¼Œæˆ–ä»ç»™å®šåˆ—è¡¨ä¸­é€‰æ‹©ä¸€ä¸ªå·¥å…·ã€‚

```
# å¼ºåˆ¶å¿…é¡»è°ƒç”¨ multiply å·¥å…·
model_force = model.bind_tools([multiply], tool_choice="multiply")
```

è¿™åœ¨æ„å»ºç¡®å®šæ€§è¡Œä¸ºçš„ Agent æ—¶éå¸¸æœ‰ç”¨ã€‚

###### âœ… å·¥å…·çš„æœ€ä½³å®è·µ

| å»ºè®®                       | è¯´æ˜                                                  |
| -------------------------- | ----------------------------------------------------- |
| **å·¥å…·èŒè´£å•ä¸€**           | ç®€å•ã€åŠŸèƒ½æ˜ç¡®çš„å·¥å…·æ›´å®¹æ˜“è¢«æ¨¡å‹æ­£ç¡®ä½¿ç”¨ã€‚            |
| **æä¾›æ¸…æ™°çš„åç§°å’Œæè¿°**   | å·¥å…·çš„å‡½æ•°åå’Œ docstring æ˜¯æ¨¡å‹ç†è§£å…¶ç”¨é€”çš„å…³é”®ã€‚     |
| **é¿å…å·¥å…·è¿‡å¤š**           | ä»å¤§é‡å·¥å…·ä¸­é€‰æ‹©ä¼šå¢åŠ æ¨¡å‹çš„å†³ç­–éš¾åº¦ã€‚                |
| **ä½¿ç”¨æ”¯æŒå·¥å…·è°ƒç”¨çš„æ¨¡å‹** | ç»è¿‡å¾®è°ƒçš„æ¨¡å‹ï¼ˆå¦‚ llama3.1ï¼‰åœ¨å·¥å…·è°ƒç”¨æ–¹é¢è¡¨ç°æ›´å¥½ã€‚ |

------

###### ä¸ LangGraph é›†æˆ

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œé€šå¸¸ä¸ä¼šæ‰‹åŠ¨æ£€æŸ¥ `tool_calls`ã€‚**LangGraph** æä¾›äº† `ToolNode` ç­‰é¢„æ„å»ºç»„ä»¶ï¼Œå¯ä»¥è‡ªåŠ¨ä»£è¡¨ç”¨æˆ·æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œå¤§å¤§ç®€åŒ–å¼€å‘ã€‚

```
# ä¼ªä»£ç ç¤ºä¾‹ï¼ˆLangGraph ä¸­çš„ ToolNodeï¼‰
from langgraph.prebuilt import ToolNode

tool_node = ToolNode([multiply])  # è‡ªåŠ¨æ‰§è¡Œ multiply å·¥å…·
```

------

##### 2.5.4 æ€»ç»“

**å·¥å…·è°ƒç”¨** æ˜¯è®© AI æ¨¡å‹â€œåŠ¨èµ·æ¥â€çš„å…³é”®æœºåˆ¶ï¼š

- ä½¿ç”¨ `@tool` åˆ›å»ºå·¥å…·ã€‚
- ä½¿ç”¨ `.bind_tools()` å°†å·¥å…·ç»‘å®šåˆ°æ¨¡å‹ã€‚
- æ¨¡å‹æ ¹æ®è¾“å…¥å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·ã€‚
- å“åº”ä¸­çš„ `tool_calls` åŒ…å«äº†æ‰§è¡Œæ‰€éœ€çš„æ‰€æœ‰ä¿¡æ¯ã€‚
- æ”¯æŒå¼ºåˆ¶è°ƒç”¨ã€æµå¼ä¼ è¾“ã€é”™è¯¯å¤„ç†ç­‰é«˜çº§åŠŸèƒ½ã€‚

å®ƒæ˜¯æ„å»º**æ™ºèƒ½ä»£ç†**ï¼ˆAgentï¼‰ã€**è‡ªåŠ¨åŒ–å·¥ä½œæµ**å’Œ**å¢å¼ºå‹é—®ç­”ç³»ç»Ÿ**çš„åŸºç¡€ã€‚ç»“åˆ `LCEL` å’Œ `LangGraph`ï¼Œä½ å¯ä»¥æ„å»ºå‡ºåŠŸèƒ½å¼ºå¤§ã€å¯ç»´æŠ¤çš„ç”Ÿäº§çº§ AI åº”ç”¨ã€‚



#### 2.6 æ£€ç´¢å™¨ï¼ˆRetrieversï¼‰

###### 2.6.1 ä»€ä¹ˆæ˜¯æ£€ç´¢å™¨ï¼ˆRetrieverï¼‰ï¼Ÿ

**æ£€ç´¢å™¨ï¼ˆRetrieverï¼‰** æ˜¯ LangChain ä¸­ç”¨äºä»æ•°æ®æºä¸­**è·å–ç›¸å…³æ–‡æ¡£**çš„ç»„ä»¶ã€‚å®ƒæ˜¯ä¸€ä¸ªæ¥å£ï¼Œå®šä¹‰äº†ä¸€ä¸ªç®€å•çš„æ–¹æ³•ï¼š

```
def invoke(query: str) -> List[Document]
```

å³ï¼šè¾“å…¥ä¸€ä¸ªæŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œè¿”å›ä¸€ç»„ç›¸å…³çš„ `Document` å¯¹è±¡ã€‚

> âœ… ä¸ `PromptTemplate`ã€`LLM` å¹¶åˆ—ï¼Œæ˜¯æ„å»º RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ä¹‹ä¸€ã€‚

------

##### 2.6.2 Retriever vs LLMï¼šå…³é”®åŒºåˆ«

| ç‰¹æ€§         | Retriever                              | LLM                                     |
| ------------ | -------------------------------------- | --------------------------------------- |
| è¾“å…¥         | `str` æˆ– `dict`                        | `str` / `PromptValue` / `List[Message]` |
| è¾“å‡º         | `List[Document]`                       | `str` / `ChatResult`                    |
| æ¥å£æ–¹æ³•     | `.invoke()` / `.batch()` / `.stream()` | åŒå·¦                                    |
| æ˜¯å¦å¯ç¼“å­˜   | âœ… æ˜¯                                   | âœ… æ˜¯                                    |
| æ˜¯å¦æ”¯æŒæµå¼ | âŒ å¦ï¼ˆè¿”å›å®Œæ•´åˆ—è¡¨ï¼‰                   | âœ… æ˜¯                                    |

> ğŸ“Œ æç¤ºï¼šRetriever çš„è¾“å‡ºé€šå¸¸ä½œä¸ºä¸Šä¸‹æ–‡è¾“å…¥ç»™ LLMï¼Œç”¨äºç”Ÿæˆæœ€ç»ˆå›ç­”ã€‚

##### 2.6.3 æ ¸å¿ƒæ–¹æ³•ï¼ˆStandard Interfaceï¼‰

æ‰€æœ‰ Retriever éƒ½å®ç°ä»¥ä¸‹æ–¹æ³•ï¼š

| æ–¹æ³•              | è¯´æ˜                            |
| ----------------- | ------------------------------- |
| `.invoke(query)`  | å•æ¬¡æ£€ç´¢ï¼Œè¿”å› `List[Document]` |
| `.batch(queries)` | æ‰¹é‡æ£€ç´¢å¤šä¸ªæŸ¥è¯¢                |
| `.stream(query)`  | âŒ ä¸æ”¯æŒæµå¼ï¼ˆæ•´ä½“è¿”å›ï¼‰        |
|                   |                                 |

```
docs = retriever.invoke("é‡å­è®¡ç®—æ˜¯ä»€ä¹ˆï¼Ÿ")
print(len(docs))  # è¾“å‡ºï¼š4
```

##### 2.6.4 å¸¸è§æ£€ç´¢å™¨ç±»å‹

LangChain æä¾›äº†å¤šç§å†…ç½® Retrieverï¼Œé€‚ç”¨äºä¸åŒåœºæ™¯ï¼š

###### 1. å‘é‡å­˜å‚¨æ£€ç´¢å™¨ï¼ˆVectorStoreRetrieverï¼‰

æœ€å¸¸ç”¨çš„ç±»å‹ï¼ŒåŸºäºå‘é‡ç›¸ä¼¼åº¦æ£€ç´¢ã€‚

```
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

vectorstore = Chroma(embedding_function=OpenAIEmbeddings())
retriever = vectorstore.as_retriever()  # è¿”å› Retriever æ¥å£
```

âœ… æ”¯æŒå‚æ•°ï¼š

- `k`: è¿”å›æ–‡æ¡£æ•°
- `search_type`: `similarity`ï¼ˆé»˜è®¤ï¼‰ã€`mmr`ï¼ˆæœ€å¤§è¾¹é™…ç›¸å…³æ€§ï¼‰ã€`similarity_score_threshold`

```
retriever = vectorstore.as_retriever(
    search_type="similarity_score_threshold",
    search_kwargs={"score_threshold": 0.75}
)
```

------

###### 2. BM25Retrieverï¼ˆå…³é”®è¯åŒ¹é…ï¼‰

åŸºäº BM25 ç®—æ³•è¿›è¡Œ**å…³é”®è¯æ£€ç´¢**ï¼Œé€‚åˆç²¾ç¡®åŒ¹é…æœ¯è¯­ã€‚

```
from langchain.retrievers import BM25Retriever

docs = ["çŒ«å–œæ¬¢çˆ¬æ ‘", "ç‹—å–œæ¬¢è¿½çƒ", "é¸Ÿä¼šé£"]
retriever = BM25Retriever.from_texts(docs, k=1)

result = retriever.invoke("çŒ«å–œæ¬¢ä»€ä¹ˆï¼Ÿ")
# è¿”å›æœ€åŒ¹é…çš„æ–‡æ¡£
```

> âœ… ä¼˜ç‚¹ï¼šæ— éœ€åµŒå…¥æ¨¡å‹ï¼Œé€‚åˆä¸“ä¸šæœ¯è¯­æ£€ç´¢
>  âŒ ç¼ºç‚¹ï¼šæ— æ³•ç†è§£è¯­ä¹‰

------

###### 3. EnsembleRetrieverï¼ˆæ··åˆæ£€ç´¢ï¼‰

ç»„åˆå¤šä¸ªæ£€ç´¢å™¨çš„ç»“æœï¼Œæå‡å¬å›ç‡ã€‚

```
from langchain.retrievers import EnsembleRetriever

ensemble = EnsembleRetriever(
    retrievers=[vectorstore_retriever, bm25_retriever],
    weights=[0.5, 0.5]
)

result = ensemble.invoke("åŠ¨ç‰©çš„ä¹ æ€§")
```

> ä½¿ç”¨ **RRFï¼ˆå€’æ•°æ’åºèåˆï¼‰** ç®—æ³•å¯¹ç»“æœå»é‡å¹¶æ’åºã€‚

###### 4. ContextualCompressionRetrieverï¼ˆä¸Šä¸‹æ–‡å‹ç¼©ï¼‰

å…ˆæ£€ç´¢ï¼Œå†ç”¨ LLM **å‹ç¼©æˆ–è¿‡æ»¤**ä¸ç›¸å…³çš„å†…å®¹ã€‚

```
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor

compressor = LLMChainExtractor.from_llm(llm)
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=vectorstore_retriever
)
```

> âœ… ä¼˜ç‚¹ï¼šå‡å°‘å™ªå£°ï¼Œæå‡ç”Ÿæˆè´¨é‡
>  âš ï¸ ç¼ºç‚¹ï¼šå¢åŠ å»¶è¿Ÿå’Œæˆæœ¬

###### 5. ParentDocumentRetrieverï¼ˆçˆ¶å­æ–‡æ¡£æ£€ç´¢ï¼‰

é€‚ç”¨äºé•¿æ–‡æ¡£åˆ‡åˆ†åœºæ™¯ï¼š**å°å—æ£€ç´¢ + å¤§å—ç”Ÿæˆ**ã€‚

æµç¨‹ï¼š

1. å°†æ–‡æ¡£åˆ‡åˆ†ä¸ºå° chunkï¼ˆç”¨äºæ£€ç´¢ï¼‰
2. æ£€ç´¢åˆ°å° chunk åï¼Œè¿”å›å…¶æ‰€å±çš„â€œçˆ¶æ–‡æ¡£â€ï¼ˆå¤§å—ï¼‰

```
from langchain.retrievers import ParentDocumentRetriever
from langchain_community.vectorstores import Chroma
from langchain_community.storage import InMemoryStore

retriever = ParentDocumentRetriever(
    vectorstore=Chroma(...),
    docstore=InMemoryStore(),
    child_splitter=RecursiveCharacterTextSplitter(chunk_size=200),
    parent_splitter=RecursiveCharacterTextSplitter(chunk_size=1000),
)
```

> âœ… é€‚ç”¨ï¼šä¹¦ç±ã€é•¿æŠ¥å‘Šã€æ³•å¾‹æ¡æ–‡ç­‰é•¿æ–‡æœ¬ RAG

###### 6. TimeWeightedVectorStoreRetrieverï¼ˆæ—¶é—´åŠ æƒï¼‰

ä¸ºæ–‡æ¡£æ·»åŠ æ—¶é—´è¡°å‡å› å­ï¼Œ**è¶Šæ–°çš„æ–‡æ¡£æƒé‡è¶Šé«˜**ã€‚

```
from langchain.retrievers import TimeWeightedVectorStoreRetriever

retriever = TimeWeightedVectorStoreRetriever(
    vectorstore=vectorstore,
    decay_rate=0.01,
    k=2
)
```

> âœ… é€‚ç”¨ï¼šè®°å¿†ç³»ç»Ÿã€ç”¨æˆ·è¡Œä¸ºè¿½è¸ªã€æ–°é—»æ¨è

###### 7. KNNRetrieverï¼ˆKè¿‘é‚»ï¼‰

ç›´æ¥åœ¨ DataFrame æˆ– NumPy æ•°ç»„ä¸Šåš KNN æ£€ç´¢ã€‚

```
from langchain.retrievers import KNNRetriever
import pandas as pd

df = pd.DataFrame({"text": ["æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ "], "embedding": [[1,2], [3,4]]})
retriever = KNNRetriever(df=df, text_column="text", embedding_column="embedding")
```

> âœ… é€‚åˆç»“æ„åŒ–æ•°æ® + åµŒå…¥æ··åˆæ£€ç´¢

##### 2.6.5 é«˜çº§åŠŸèƒ½

###### 1. å¤šæŸ¥è¯¢ç”Ÿæˆï¼ˆMulti-Query Retrieverï¼‰

ç”¨ LLM ä¸ºåŸå§‹æŸ¥è¯¢ç”Ÿæˆå¤šä¸ªå˜ä½“ï¼Œæå‡å¬å›ç‡ã€‚

```
from langchain.retrievers import MultiQueryRetriever

retriever = MultiQueryRetriever.from_llm(
    retriever=vectorstore.as_retriever(),
    llm=ChatOpenAI()
)

# ç”¨æˆ·é—®ï¼šâ€œæ°”å€™å˜åŒ–çš„å½±å“â€
# å¯èƒ½ç”Ÿæˆï¼šâ€œå…¨çƒå˜æš–çš„åæœâ€ã€â€œæ°”å€™å˜æš–å¯¹ç”Ÿæ€çš„å½±å“â€ç­‰
```

###### 2. è‡ªå®šä¹‰ Retriever

ç»§æ‰¿ `BaseRetriever` å®ç°è‡ªå®šä¹‰é€»è¾‘ï¼š

```
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document

class MyRetriever(BaseRetriever):
    def _get_relevant_documents(self, query):
        return [Document(page_content="è‡ªå®šä¹‰ç»“æœ")]

retriever = MyRetriever()
```

##### 2.6.6 ä½¿ç”¨åœºæ™¯å»ºè®®

| åœºæ™¯         | æ¨è Retriever                             |
| ------------ | ------------------------------------------ |
| é€šç”¨è¯­ä¹‰æ£€ç´¢ | `VectorStoreRetriever`                     |
| ä¸“ä¸šæœ¯è¯­åŒ¹é… | `BM25Retriever`                            |
| æé«˜å¬å›ç‡   | `EnsembleRetriever`ã€`MultiQueryRetriever` |
| é•¿æ–‡æ¡£å¤„ç†   | `ParentDocumentRetriever`                  |
| å®æ—¶æ€§è¦æ±‚é«˜ | `TimeWeightedVectorStoreRetriever`         |
| éœ€è¦è¿‡æ»¤å™ªå£° | `ContextualCompressionRetriever`           |

##### 2.6.7 ç¤ºä¾‹

```python
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_ollama import OllamaEmbeddings  # âœ… æ–°å¯¼å…¥
from langchain_community.vectorstores import Chroma

# 1. åŠ è½½æ–‡æ¡£
loader = TextLoader("data.txt", encoding="utf-8")
docs = loader.load()

# 2. åˆ†å‰²æ–‡æœ¬
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=300,
    chunk_overlap=50
)
splits = text_splitter.split_documents(docs)

# 3. ä½¿ç”¨ langchain-ollama çš„åµŒå…¥æ¨¡å‹
embeddings = OllamaEmbeddings(
    model="nomic-embed-text",
    base_url="http://localhost:11434",
    keep_alive=-1  # -1 è¡¨ç¤ºæ°¸ä¹…ä¿ç•™åœ¨å†…å­˜ä¸­
)

# 4. å­˜å…¥å‘é‡æ•°æ®åº“
vectorstore = Chroma.from_documents(
    documents=splits,
    embedding=embeddings,
    persist_directory="./chroma_db_nomic"
)

print("âœ… æ•°æ®å·²ä½¿ç”¨ nomic-embed-text åµŒå…¥å¹¶å­˜å…¥å‘é‡æ•°æ®åº“ï¼")

# 5. åˆ›å»ºæ£€ç´¢å™¨
retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

# 6. æŸ¥è¯¢æµ‹è¯•
query = "LangChain æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ"
result = retriever.invoke(query)

print(f"\nğŸ” æŸ¥è¯¢: {query}")
for i, doc in enumerate(result):
    print(f"\n--- ç»“æœ {i+1} ---")
    print(doc.page_content)

```

